{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get dependencies\n",
    "import seaborn as sns\n",
    "import time\n",
    "from itertools import combinations \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import os\n",
    "from numpy import array\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import KFold\n",
    "#load the dataframe\n",
    "all_state = pd.read_csv(\"allstate_sample.csv\")\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10357, 133)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont6</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.490651</td>\n",
       "      <td>0.992293</td>\n",
       "      <td>0.33372</td>\n",
       "      <td>0.42289</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.797841</td>\n",
       "      <td>0.785706</td>\n",
       "      <td>0.189489</td>\n",
       "      <td>0.798932</td>\n",
       "      <td>1496.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186254</td>\n",
       "      <td>0.317274</td>\n",
       "      <td>0.27797</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.24355</td>\n",
       "      <td>0.180456</td>\n",
       "      <td>0.178698</td>\n",
       "      <td>0.304350</td>\n",
       "      <td>0.383475</td>\n",
       "      <td>3631.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.367193</td>\n",
       "      <td>0.266569</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.58529</td>\n",
       "      <td>0.20496</td>\n",
       "      <td>0.254180</td>\n",
       "      <td>0.250169</td>\n",
       "      <td>0.509999</td>\n",
       "      <td>0.740503</td>\n",
       "      <td>1599.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350956</td>\n",
       "      <td>0.363768</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>0.44352</td>\n",
       "      <td>0.39599</td>\n",
       "      <td>0.341813</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.339244</td>\n",
       "      <td>0.236627</td>\n",
       "      <td>9270.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763644</td>\n",
       "      <td>0.646277</td>\n",
       "      <td>0.25918</td>\n",
       "      <td>0.49790</td>\n",
       "      <td>0.61459</td>\n",
       "      <td>0.614915</td>\n",
       "      <td>0.601984</td>\n",
       "      <td>0.808455</td>\n",
       "      <td>0.221004</td>\n",
       "      <td>2790.16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 131 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10   ...        cont6  \\\n",
       "0    A    A    A    A    B    A    A    A    A     A   ...     0.490651   \n",
       "1    A    B    A    B    A    A    A    A    B     A   ...     0.186254   \n",
       "2    A    B    A    B    A    A    A    A    B     A   ...     0.367193   \n",
       "3    A    B    A    A    A    A    A    A    B     B   ...     0.350956   \n",
       "4    A    B    A    A    A    A    A    A    A     A   ...     0.763644   \n",
       "\n",
       "      cont7    cont8    cont9   cont10    cont11    cont12    cont13  \\\n",
       "0  0.992293  0.33372  0.42289  0.60401  0.797841  0.785706  0.189489   \n",
       "1  0.317274  0.27797  0.32128  0.24355  0.180456  0.178698  0.304350   \n",
       "2  0.266569  0.60087  0.58529  0.20496  0.254180  0.250169  0.509999   \n",
       "3  0.363768  0.58354  0.44352  0.39599  0.341813  0.352251  0.339244   \n",
       "4  0.646277  0.25918  0.49790  0.61459  0.614915  0.601984  0.808455   \n",
       "\n",
       "     cont14     loss  \n",
       "0  0.798932  1496.42  \n",
       "1  0.383475  3631.23  \n",
       "2  0.740503  1599.79  \n",
       "3  0.236627  9270.33  \n",
       "4  0.221004  2790.16  \n",
       "\n",
       "[5 rows x 131 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_state.shape)\n",
    "#show distribution of lost \n",
    "plt.hist(all_state['loss'])\n",
    "plt.show()\n",
    "#distribution is right skewwed, not normal\n",
    "#does not matter with naive bayes\n",
    "all_state.dtypes\n",
    "#only cat1 through cat116 are type object\n",
    "#drop unamed:0 and id\n",
    "all_state = all_state.drop(['Unnamed: 0','id'],axis=1)\n",
    "all_state.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_state.iloc[:,115]\n",
    "#create range from 0 to 115 for chosing categorial variables\n",
    "#how should you bin the responses though..?\n",
    "#im going to start with a binary classifier first\n",
    "#make function to bin, might need this later\n",
    "def bin_loss_all_state(df,col_to_cut,col_name,ranges,labels):\n",
    "    df[col_name] = pd.cut(df[col_to_cut],ranges,labels = labels)\n",
    "    response = df[col_name]\n",
    "    return(response) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat1</th>\n",
       "      <th>cat2</th>\n",
       "      <th>cat3</th>\n",
       "      <th>cat4</th>\n",
       "      <th>cat5</th>\n",
       "      <th>cat6</th>\n",
       "      <th>cat7</th>\n",
       "      <th>cat8</th>\n",
       "      <th>cat9</th>\n",
       "      <th>cat10</th>\n",
       "      <th>...</th>\n",
       "      <th>cont7</th>\n",
       "      <th>cont8</th>\n",
       "      <th>cont9</th>\n",
       "      <th>cont10</th>\n",
       "      <th>cont11</th>\n",
       "      <th>cont12</th>\n",
       "      <th>cont13</th>\n",
       "      <th>cont14</th>\n",
       "      <th>loss</th>\n",
       "      <th>BinLoss1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.992293</td>\n",
       "      <td>0.33372</td>\n",
       "      <td>0.42289</td>\n",
       "      <td>0.60401</td>\n",
       "      <td>0.797841</td>\n",
       "      <td>0.785706</td>\n",
       "      <td>0.189489</td>\n",
       "      <td>0.798932</td>\n",
       "      <td>1496.42</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317274</td>\n",
       "      <td>0.27797</td>\n",
       "      <td>0.32128</td>\n",
       "      <td>0.24355</td>\n",
       "      <td>0.180456</td>\n",
       "      <td>0.178698</td>\n",
       "      <td>0.304350</td>\n",
       "      <td>0.383475</td>\n",
       "      <td>3631.23</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266569</td>\n",
       "      <td>0.60087</td>\n",
       "      <td>0.58529</td>\n",
       "      <td>0.20496</td>\n",
       "      <td>0.254180</td>\n",
       "      <td>0.250169</td>\n",
       "      <td>0.509999</td>\n",
       "      <td>0.740503</td>\n",
       "      <td>1599.79</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>B</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363768</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>0.44352</td>\n",
       "      <td>0.39599</td>\n",
       "      <td>0.341813</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>0.339244</td>\n",
       "      <td>0.236627</td>\n",
       "      <td>9270.33</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>0.646277</td>\n",
       "      <td>0.25918</td>\n",
       "      <td>0.49790</td>\n",
       "      <td>0.61459</td>\n",
       "      <td>0.614915</td>\n",
       "      <td>0.601984</td>\n",
       "      <td>0.808455</td>\n",
       "      <td>0.221004</td>\n",
       "      <td>2790.16</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 132 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cat1 cat2 cat3 cat4 cat5 cat6 cat7 cat8 cat9 cat10   ...        cont7  \\\n",
       "0    A    A    A    A    B    A    A    A    A     A   ...     0.992293   \n",
       "1    A    B    A    B    A    A    A    A    B     A   ...     0.317274   \n",
       "2    A    B    A    B    A    A    A    A    B     A   ...     0.266569   \n",
       "3    A    B    A    A    A    A    A    A    B     B   ...     0.363768   \n",
       "4    A    B    A    A    A    A    A    A    A     A   ...     0.646277   \n",
       "\n",
       "     cont8    cont9   cont10    cont11    cont12    cont13    cont14     loss  \\\n",
       "0  0.33372  0.42289  0.60401  0.797841  0.785706  0.189489  0.798932  1496.42   \n",
       "1  0.27797  0.32128  0.24355  0.180456  0.178698  0.304350  0.383475  3631.23   \n",
       "2  0.60087  0.58529  0.20496  0.254180  0.250169  0.509999  0.740503  1599.79   \n",
       "3  0.58354  0.44352  0.39599  0.341813  0.352251  0.339244  0.236627  9270.33   \n",
       "4  0.25918  0.49790  0.61459  0.614915  0.601984  0.808455  0.221004  2790.16   \n",
       "\n",
       "  BinLoss1  \n",
       "0      Low  \n",
       "1     High  \n",
       "2      Low  \n",
       "3     High  \n",
       "4     High  \n",
       "\n",
       "[5 rows x 132 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a binary response to test\n",
    "all_state[\"BinLoss1\"] = pd.cut(all_state['loss'], [0,2000,100000], labels = [\"Low\", \"High\"])\n",
    "all_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low     6724\n",
       "High    3633\n",
       "Name: BinLogLoss, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try taking the log off loss and see what happens too\n",
    "all_state['log_loss'] = np.log(all_state['loss'])\n",
    "all_state['log_loss'].describe()\n",
    "#try binning log_loss\n",
    "all_state[\"BinLogLoss\"] = pd.cut(all_state['log_loss'], [0,8,10.6], labels = [\"Low\", \"High\"])\n",
    "all_state['BinLogLoss'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>iteration_number</th>\n",
       "      <th>num_variables</th>\n",
       "      <th>selection_variables</th>\n",
       "      <th>upper_bound_low_cat</th>\n",
       "      <th>accuracy_scores</th>\n",
       "      <th>misclass_scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[13, 28, 20, 11, 17]</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.977117</td>\n",
       "      <td>0.022883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[13, 28, 20, 11, 17]</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.951917</td>\n",
       "      <td>0.048083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[13, 28, 20, 11, 17]</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.909530</td>\n",
       "      <td>0.090470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[13, 28, 20, 11, 17]</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.855267</td>\n",
       "      <td>0.144733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>[13, 28, 20, 11, 17]</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.784107</td>\n",
       "      <td>0.215893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  iteration_number  num_variables   selection_variables  \\\n",
       "0           0                 0              5  [13, 28, 20, 11, 17]   \n",
       "1           1                 0              5  [13, 28, 20, 11, 17]   \n",
       "2           2                 0              5  [13, 28, 20, 11, 17]   \n",
       "3           3                 0              5  [13, 28, 20, 11, 17]   \n",
       "4           4                 0              5  [13, 28, 20, 11, 17]   \n",
       "\n",
       "   upper_bound_low_cat  accuracy_scores  misclass_scores  \n",
       "0                  6.2         0.977117         0.022883  \n",
       "1                  6.4         0.951917         0.048083  \n",
       "2                  6.6         0.909530         0.090470  \n",
       "3                  6.8         0.855267         0.144733  \n",
       "4                  7.0         0.784107         0.215893  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_state_models = pd.read_csv(\"all_state_models_NB.csv\")\n",
    "all_state_models.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Low     5896\n",
       "High    4461\n",
       "Name: BinLogLoss, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get distributions for logloss at 7.8\n",
    "#try taking the log off loss and see what happens too\n",
    "all_state['log_loss'] = np.log(all_state['loss'])\n",
    "all_state['log_loss'].describe()\n",
    "#try binning log_loss\n",
    "all_state[\"BinLogLoss\"] = pd.cut(all_state['log_loss'], [0,7.8,10.6], labels = [\"Low\", \"High\"])\n",
    "all_state['BinLogLoss'].value_counts()\n",
    "#low bin log loss will 7.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for naive bayes, already said 30 vars and cut off for logloss low at 7.8 \n",
    "low_interval = [0,7.8,12]\n",
    "#create new binned response\n",
    "response_1 = bin_loss_all_state(all_state,'log_loss','BinLogLoss',low_interval,[\"Low\", \"High\"])\n",
    "accuracy_30_values = []\n",
    "misclass_30_values = []\n",
    "selection_variables =[]\n",
    "for i in range(1,500):\n",
    "    #get random sample of 30 predictors\n",
    "    selection = list(np.random.choice(range(1,116),size=30,replace=False))\n",
    "    selection_variables.append(selection)\n",
    "    #get the design matrix \n",
    "    X = all_state.iloc[:,selection]\n",
    "    #encode the cateogorival variables\n",
    "    encoder = preprocessing.OneHotEncoder()\n",
    "    encoder.fit(X)\n",
    "    X_encoded = encoder.transform(X) ##this is not an array yet\n",
    "    #fit the classifier\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_encoded.toarray(),response_1)\n",
    "    #predict and get accuracy\n",
    "    predictions = clf.predict(X_encoded.toarray())\n",
    "    #get accuracy rate\n",
    "    accuracy_30 = np.mean(predictions == response_1)\n",
    "    misclass_30 = np.mean(predictions != response_1)\n",
    "    #add to list\n",
    "    accuracy_30_values.append(accuracy_30)\n",
    "    misclass_30_values.append(misclass_30_values)\n",
    "plt.hist(accuracy_30_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.750965250965251, 0.7171814671814671, 0.7393822393822393, 0.7335907335907336, 0.747104247104247, 0.7393822393822393, 0.7480694980694981, 0.7410628019323672, 0.7613526570048309, 0.7623188405797101]\n",
      "0.7440409975192583\n"
     ]
    }
   ],
   "source": [
    "#identifiy selection of features that give the highest accuracy, given the reponse\n",
    "optimized_features = selection_variables[np.argmax(accuracy_30_values)]\n",
    "#allocate matrices\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit(all_state.iloc[:,optimized_features])\n",
    "X_optimized_encoded = encoder.transform(all_state.iloc[:,optimized_features]) #this is not an array yet\n",
    "#cast X_optimized_encoded as array\n",
    "X = X_optimized_encoded.toarray()\n",
    "y = response_1\n",
    "#begin CV\n",
    "cv = KFold(n_splits=10, random_state=45, shuffle=False)\n",
    "cv_accuracy_scores = []\n",
    "cv_misclass_scores = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    #assign training and testing matrices\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    #fit the classifier\n",
    "    clf = MultinomialNB()\n",
    "    clf.fit(X_train,y_train)\n",
    "    #predict and get accuracy\n",
    "    cv_predictions = clf.predict(X_test)\n",
    "    #get accuracy rate\n",
    "    cv_accuracy_38 = np.mean(cv_predictions == y_test)\n",
    "    cv_misclass_38 = np.mean(cv_predictions != y_test)\n",
    "    #add\n",
    "    cv_accuracy_scores.append(cv_accuracy_38)\n",
    "    cv_misclass_scores.append(cv_misclass_38)\n",
    "print(cv_accuracy_scores)\n",
    "print(np.mean(cv_accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7529207299411026"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using optimized features get predictions, remember this is from the whole set\n",
    "clf_NB = MultinomialNB()\n",
    "clf_NB.fit(X,y)\n",
    "predictions_NB = clf_NB.predict(X)\n",
    "accuracy_score(predictions_NB,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>num_variables</th>\n",
       "      <th>selected_variables</th>\n",
       "      <th>model_number</th>\n",
       "      <th>num_neighbors</th>\n",
       "      <th>accuracy_knn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[13]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.709182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[8]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.556918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>[4]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.499372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>[5]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.605291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[9]</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  num_variables selected_variables  model_number  num_neighbors  \\\n",
       "0           0              1               [13]             1              2   \n",
       "1           1              1                [8]             1              3   \n",
       "2           2              1                [4]             1              4   \n",
       "3           3              1                [5]             1              5   \n",
       "4           4              1                [9]             2              2   \n",
       "\n",
       "   accuracy_knn  \n",
       "0      0.709182  \n",
       "1      0.556918  \n",
       "2      0.499372  \n",
       "3      0.605291  \n",
       "4      0.475910  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now knn\n",
    "#use continuous features from all state\n",
    "all_state.head()\n",
    "cont_variables = [vars for vars in all_state.columns if 'cont' in vars]\n",
    "cont_variables\n",
    "#lets try a first stab at knn using all 14\n",
    "#but first we need to standardize the cont variables\n",
    "all_state_cont = all_state[cont_variables]\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(all_state_cont)\n",
    "all_state_cont_scaled = scaler.transform(all_state_cont)\n",
    "#plt.hist(all_state_cont_scaled[:,3])\n",
    "#plt.show()\n",
    "all_state_models_knn = pd.read_csv(\"all_state_models_knn.csv\")\n",
    "all_state_models_knn.head()\n",
    "#we already said 3 neighbors and 5 of the continuous variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7045476489330887\n"
     ]
    }
   ],
   "source": [
    "#write knn function that takes in design matrix and response, the num neighbors and the\n",
    "#minkowski distance parameter and returns accuracy\n",
    "def knn(X,y,n,p):\n",
    "    #fit the classifier\n",
    "    classifier = KNeighborsClassifier(n_neighbors=n, weights = 'uniform', algorithm = 'kd_tree',p=p)  \n",
    "    classifier.fit(X, y)\n",
    "    y_pred = classifier.predict(X)\n",
    "    return(accuracy_score(y_pred,y))\n",
    "#test function\n",
    "print(knn(all_state_cont_scaled,response_1,5,3))\n",
    "#function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Mon Sep 16 23:53:34 2019\n",
      "50 Mon Sep 16 23:53:53 2019\n",
      "100 Mon Sep 16 23:54:13 2019\n",
      "150 Mon Sep 16 23:54:32 2019\n",
      "200 Mon Sep 16 23:54:51 2019\n",
      "250 Mon Sep 16 23:55:12 2019\n",
      "300 Mon Sep 16 23:55:33 2019\n",
      "350 Mon Sep 16 23:55:54 2019\n",
      "400 Mon Sep 16 23:56:16 2019\n",
      "450 Mon Sep 16 23:56:38 2019\n",
      "500 Mon Sep 16 23:56:58 2019\n",
      "550 Mon Sep 16 23:57:18 2019\n",
      "600 Mon Sep 16 23:57:37 2019\n",
      "650 Mon Sep 16 23:57:57 2019\n"
     ]
    }
   ],
   "source": [
    "#lets estimate the distribution of all 5 feature knn models with num neighbors equal to 3, do 1000 times\n",
    "#can alter to try 14\n",
    "accuracy_knn_5cont_3neigh = []\n",
    "variables = []\n",
    "for i in range(0,700):\n",
    "    if i%50 == 0:\n",
    "        print(i,time.ctime())\n",
    "    #store random seletion of variables\n",
    "    selection = np.random.choice(range(0,all_state_cont_scaled.shape[1]),size=14,replace=False)\n",
    "    #get variables from standard\n",
    "    X = all_state_cont_scaled[:,selection]\n",
    "    y = response_1\n",
    "    #get accuracy, use squared distance\n",
    "    accuracy = knn(X,y,3,2)\n",
    "    #store values\n",
    "    accuracy_knn_5cont_3neigh.append(accuracy)\n",
    "    variables.append(selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQfElEQVR4nO3df6yeZ13H8feHlYEi0P04W5a2sxAKshAZ8wSLGAJUyVYM3R/MQJCVpbHGTAJC1Okf4q8/wESnS3CmMqQj/JoIrsEJLgWCipucsVF+DNxhwnrSuh5gK+KCOPj6x3NVztpzdu62z3NOe+39Sp7c9/29r+c832trPr13nfu5l6pCktSXx612A5Kk8TPcJalDhrskdchwl6QOGe6S1KE1q90AwLnnnlsbN25c7TYk6bRyxx13fKOqphY7d0qE+8aNG5mZmVntNiTptJLk60udc1lGkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdWjZcE/yrCR3LXh9O8kbk5yd5NYk97TtWW18klyXZDbJviSXTH4akqSFlg33qvpKVV1cVRcDPwU8BHwYuAbYW1WbgL3tGOAyYFN77QSun0TjkqSlHe+yzBbgq1X1dWAbsLvVdwOXt/1twI01chuwNskFY+lWkjTI8X5D9VXA+9r++VV1EKCqDiY5r9XXAfsXvGeu1Q4u/EFJdjK6sufCCy88zjaklbHxmr9ftc/+2ltfvmqfrdPf4Cv3JGcCrwD+Zrmhi9SO+d89VdWuqpququmpqUUfjSBJOkHHsyxzGfDZqrq/Hd9/ZLmlbQ+1+hywYcH71gMHTrZRSdJwxxPur+aHSzIAe4DtbX87cPOC+pXtrpnNwOEjyzeSpJUxaM09yY8CPw/8yoLyW4GbkuwA7gOuaPVbgK3ALKM7a64aW7eSpEEGhXtVPQScc1Ttm4zunjl6bAFXj6U7SdIJ8RuqktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0KBwT7I2yQeTfDnJ3UlekOTsJLcmuadtz2pjk+S6JLNJ9iW5ZLJTkCQdbeiV+58DH62qnwCeC9wNXAPsrapNwN52DHAZsKm9dgLXj7VjSdKylg33JE8BXgTcAFBV36uqB4FtwO42bDdwedvfBtxYI7cBa5NcMPbOJUlLGnLl/nRgHvjrJHcmeUeSJwHnV9VBgLY9r41fB+xf8P65VnuEJDuTzCSZmZ+fP6lJSJIeaUi4rwEuAa6vqucB/80Pl2AWk0VqdUyhaldVTVfV9NTU1KBmJUnDDAn3OWCuqm5vxx9kFPb3H1luadtDC8ZvWPD+9cCB8bQrSRpi2XCvqv8E9id5VittAb4E7AG2t9p24Oa2vwe4st01sxk4fGT5RpK0MtYMHPd64D1JzgTuBa5i9BfDTUl2APcBV7SxtwBbgVngoTZWkrSCBoV7Vd0FTC9yassiYwu4+iT7kiSdBL+hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktShQeGe5GtJPp/kriQzrXZ2kluT3NO2Z7V6klyXZDbJviSXTHICkqRjHc+V+0uq6uKqmm7H1wB7q2oTsLcdA1wGbGqvncD142pWkjTMySzLbAN2t/3dwOUL6jfWyG3A2iQXnMTnSJKO09BwL+Afk9yRZGernV9VBwHa9rxWXwfsX/DeuVZ7hCQ7k8wkmZmfnz+x7iVJi1ozcNwLq+pAkvOAW5N8+VHGZpFaHVOo2gXsApienj7mvCTpxA26cq+qA217CPgw8Hzg/iPLLW17qA2fAzYsePt64MC4GpYkLW/ZcE/ypCRPPrIPvAz4ArAH2N6GbQdubvt7gCvbXTObgcNHlm8kSStjyLLM+cCHkxwZ/96q+miSzwA3JdkB3Adc0cbfAmwFZoGHgKvG3rUk6VEtG+5VdS/w3EXq3wS2LFIv4OqxdCdJOiF+Q1WSOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0aHO5JzkhyZ5KPtOOnJbk9yT1JPpDkzFZ/Qjuebec3TqZ1SdJSjufK/Q3A3QuO3wZcW1WbgAeAHa2+A3igqp4BXNvGSZJW0KBwT7IeeDnwjnYc4KXAB9uQ3cDlbX9bO6ad39LGS5JWyNAr9z8DfhP4QTs+B3iwqh5ux3PAura/DtgP0M4fbuMfIcnOJDNJZubn50+wfUnSYpYN9yS/AByqqjsWlhcZWgPO/bBQtauqpqtqempqalCzkqRh1gwY80LgFUm2Ak8EnsLoSn5tkjXt6nw9cKCNnwM2AHNJ1gBPBb419s4lSUta9sq9qn67qtZX1UbgVcDHq+o1wCeAV7Zh24Gb2/6edkw7//GqOubKXZI0OSdzn/tvAW9KMstoTf2GVr8BOKfV3wRcc3ItSpKO15Blmf9XVZ8EPtn27wWev8iY7wJXjKE3SdIJ8huqktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR1aNtyTPDHJvyX5XJIvJvn9Vn9aktuT3JPkA0nObPUntOPZdn7jZKcgSTrakCv3/wFeWlXPBS4GLk2yGXgbcG1VbQIeAHa08TuAB6rqGcC1bZwkaQUtG+418p12+Pj2KuClwAdbfTdwedvf1o5p57ckydg6liQta9Cae5IzktwFHAJuBb4KPFhVD7chc8C6tr8O2A/Qzh8GzlnkZ+5MMpNkZn5+/uRmIUl6hEHhXlXfr6qLgfXA84FnLzasbRe7Sq9jClW7qmq6qqanpqaG9itJGuC47papqgeBTwKbgbVJ1rRT64EDbX8O2ADQzj8V+NY4mpUkDTPkbpmpJGvb/o8APwfcDXwCeGUbth24ue3vace08x+vqmOu3CVJk7Nm+SFcAOxOcgajvwxuqqqPJPkS8P4kfwTcCdzQxt8AvDvJLKMr9ldNoG9J0qNYNtyrah/wvEXq9zJafz+6/l3girF0J0k6IX5DVZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHVo23JNsSPKJJHcn+WKSN7T62UluTXJP257V6klyXZLZJPuSXDLpSUiSHmnIlfvDwJur6tnAZuDqJBcB1wB7q2oTsLcdA1wGbGqvncD1Y+9akvSolg33qjpYVZ9t+/8F3A2sA7YBu9uw3cDlbX8bcGON3AasTXLB2DuXJC3puNbck2wEngfcDpxfVQdh9BcAcF4btg7Yv+Btc60mSVohg8M9yY8Bfwu8saq+/WhDF6nVIj9vZ5KZJDPz8/ND25AkDTAo3JM8nlGwv6eqPtTK9x9ZbmnbQ60+B2xY8Pb1wIGjf2ZV7aqq6aqanpqaOtH+JUmLGHK3TIAbgLur6k8XnNoDbG/724GbF9SvbHfNbAYOH1m+kSStjDUDxrwQeC3w+SR3tdrvAG8FbkqyA7gPuKKduwXYCswCDwFXjbVjSdKylg33qvpnFl9HB9iyyPgCrj7JviRJJ8FvqEpShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1aNlwT/LOJIeSfGFB7ewktya5p23PavUkuS7JbJJ9SS6ZZPOSpMUNuXJ/F3DpUbVrgL1VtQnY244BLgM2tddO4PrxtClJOh7LhntVfQr41lHlbcDutr8buHxB/cYauQ1Ym+SCcTUrSRrmRNfcz6+qgwBte16rrwP2Lxg312rHSLIzyUySmfn5+RNsQ5K0mHH/QjWL1GqxgVW1q6qmq2p6ampqzG1I0mPbiYb7/UeWW9r2UKvPARsWjFsPHDjx9iRJJ+JEw30PsL3tbwduXlC/st01sxk4fGT5RpK0ctYsNyDJ+4AXA+cmmQPeArwVuCnJDuA+4Io2/BZgKzALPARcNYGeJUnLWDbcq+rVS5zassjYAq4+2aYkSSfHb6hKUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdWgi4Z7k0iRfSTKb5JpJfIYkaWljD/ckZwBvBy4DLgJeneSicX+OJGlpk7hyfz4wW1X3VtX3gPcD2ybwOZKkJayZwM9cB+xfcDwH/PTRg5LsBHa2w+8k+coEejnVnAt8Y7WbWGHO+QTlbWPoZOX473l1/PhSJyYR7lmkVscUqnYBuybw+aesJDNVNb3afawk5/zY4JxPPZNYlpkDNiw4Xg8cmMDnSJKWMIlw/wywKcnTkpwJvArYM4HPkSQtYezLMlX1cJJfAz4GnAG8s6q+OO7POU09ppahGuf82OCcTzGpOmY5XJJ0mvMbqpLUIcNdkjpkuE/A0McvJHllkkpyyt5ONdSQOSf5xSRfSvLFJO9d6R7Hbbk5J7kwySeS3JlkX5Ktq9HnuCR5Z5JDSb6wxPkkua7989iX5JKV7nHcBsz5NW2u+5J8OslzV7rHJVWVrzG+GP0S+avA04Ezgc8BFy0y7snAp4DbgOnV7nvScwY2AXcCZ7Xj81a77xWY8y7gV9v+RcDXVrvvk5zzi4BLgC8scX4r8A+MvuuyGbh9tXtegTn/zII/05edSnP2yn38hj5+4Q+BPwa+u5LNTciQOf8y8PaqegCgqg6tcI/jNmTOBTyl7T+V0/z7HlX1KeBbjzJkG3BjjdwGrE1ywcp0NxnLzbmqPn3kzzSjC7X1K9LYAIb7+C32+IV1CwckeR6woao+spKNTdCycwaeCTwzyb8kuS3JpSvW3WQMmfPvAb+UZA64BXj9yrS2aob8M+nZDkb/5XJKmMTjBx7rHvXxC0keB1wLvG6lGloBQx45sYbR0syLGV3d/FOS51TVgxPubVKGzPnVwLuq6k+SvAB4d5vzDybf3qoY9OiRHiV5CaNw/9nV7uUIr9zHb7nHLzwZeA7wySRfY7Q2uec0/6XqkEdOzAE3V9X/VtV/AF9hFPanqyFz3gHcBFBV/wo8kdHDpnr1mHz0SJKfBN4BbKuqb652P0cY7uP3qI9fqKrDVXVuVW2sqo2M1uleUVUzq9PuWAx55MTfAS8BSHIuo2Wae1e0y/EaMuf7gC0ASZ7NKNznV7TLlbUHuLLdNbMZOFxVB1e7qUlKciHwIeC1VfXvq93PQi7LjFkt8fiFJH8AzFRVd8/ZGTjnjwEvS/Il4PvAb5xKVznHa+Cc3wz8VZJfZ7Q88bpqt1WcjpK8j9Gy2rnt9whvAR4PUFV/yej3CluBWeAh4KrV6XR8Bsz5d4FzgL9IAvBwnSJPivTxA5LUIZdlJKlDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nq0P8BSpZbSbSn9xAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584242541276431\n"
     ]
    }
   ],
   "source": [
    "plt.hist(accuracy_knn_5cont_3neigh)\n",
    "plt.show()\n",
    "print(np.max(accuracy_knn_5cont_3neigh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.555019305019305, 0.5144787644787645, 0.525096525096525, 0.5212355212355212, 0.5521235521235521, 0.5598455598455598, 0.5115830115830116, 0.5285024154589372, 0.5285024154589372, 0.5256038647342995]\n",
      "0.5321990935034413\n"
     ]
    }
   ],
   "source": [
    "#cross validatidate with the best model\n",
    "#num features 5, neighbors 3\n",
    "#get best features\n",
    "optimized_features = variables[np.argmax(accuracy_knn_5cont_3neigh)]\n",
    "#allocate matrices\n",
    "X = all_state_cont_scaled[:,optimized_features]\n",
    "y = response_1\n",
    "\n",
    "#begin CV\n",
    "cv = KFold(n_splits=10, random_state=45, shuffle=False)\n",
    "cv_accuracy_scores = []\n",
    "cv_misclass_scores = []\n",
    "for train_index, test_index in cv.split(X):\n",
    "    #assign training and testing matrices\n",
    "    X_train, X_test, y_train, y_test = X[train_index], X[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    #fit the classifier\n",
    "    knn_clf_cv = KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "    knn_clf_cv.fit(X_train,y_train)\n",
    "    #predict and get accuracy\n",
    "    cv_predictions = knn_clf_cv.predict(X_test)\n",
    "    #get accuracy rate\n",
    "    cv_accuracy = np.mean(cv_predictions == y_test)\n",
    "    cv_misclass = np.mean(cv_predictions != y_test)\n",
    "    #add\n",
    "    cv_accuracy_scores.append(cv_accuracy)\n",
    "    cv_misclass_scores.append(cv_misclass)\n",
    "    \n",
    "print(cv_accuracy_scores)\n",
    "print(np.mean(cv_accuracy_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missclassification rate is 26.455537317756107\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#genearte ROC curve for naive bayes\n",
    "#identifiy selection of features that give the highest accuracy, given the reponse\n",
    "optimized_features = selection_variables[np.argmax(accuracy_30_values)]\n",
    "#allocate matrices\n",
    "encoder = preprocessing.OneHotEncoder()\n",
    "encoder.fit(all_state.iloc[:,optimized_features])\n",
    "X_optimized_encoded = encoder.transform(all_state.iloc[:,optimized_features]) #this is not an array yet\n",
    "#cast X_optimized_encoded as array\n",
    "X = X_optimized_encoded.toarray()\n",
    "y = response_1\n",
    "#convert y to binary\n",
    "def binarize_y(a):\n",
    "    if a == \"High\":\n",
    "        return(0)\n",
    "    else:\n",
    "        return(1)\n",
    "y_binary = y.apply(binarize_y)\n",
    "#genearte ROC curve for naive bayes\n",
    "#fit the classifier\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X,y_binary)\n",
    "#get predictions, prior is set to 50%\n",
    "print(\"missclassification rate is \"+str((sum(clf.predict(X) != y_binary) / len(y_binary))*100))\n",
    "#Print confusion matrix\n",
    "pd.crosstab(y_binary,clf.predict(X))\n",
    "#generate roc curver for multinomalNB\n",
    "thresholds = np.linspace(0,1,15)\n",
    "fpr_MNB, tpr_MNB, thresholds = roc_curve(y_binary, clf.predict_proba(X)[:,1])\n",
    "plt.plot(fpr_MNB,tpr_MNB)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7584242541276431"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get predictions from NB\n",
    "predictions_NB\n",
    "#get pridctions from knn\n",
    "knn = KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "knn.fit(all_state_cont_scaled,response_1)\n",
    "knn_predictions = knn.predict(all_state_cont_scaled)\n",
    "accuracy_score(knn_predictions,response_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binaryize both\n",
    "predictions_NB_bin = pd.Series(predictions_NB).apply(binarize_y)\n",
    "knn_predictions_bin = pd.Series(knn_predictions).apply(binarize_y)\n",
    "actual_y = response_1.apply(binarize_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn to arrays and concatnnate\n",
    "X = np.hstack((predictions_NB_bin.values.reshape((10357,1)),\n",
    "                   knn_predictions_bin.values.reshape((10357,1))))\n",
    "X.shape\n",
    "\n",
    "#the matrix equation now reads vec_y = A*vec_X\n",
    "u, s, vh = np.linalg.svd(X, full_matrices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for knn and multinb is: 0.7529207299411026\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "clf1 = KNeighborsClassifier(n_neighbors=2,p=2)\n",
    "clf2 = MultinomialNB()\n",
    "ensemble=VotingClassifier(estimators=[('knn',clf1 ), ('NB', clf2)], \n",
    "                       voting='hard', weights=[1,1]).fit(X,actual_y)\n",
    "print('The accuracy for knn and multinb is:',ensemble.score(X,actual_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([106.50412221,  42.33050853, 148.83463074, ...,  42.33050853,\n",
       "        42.33050853,  42.33050853])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(X,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
